{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FAVIVariationalTDDualControlBernoulliReward.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucaAmbrogioni/TaylorAlgebra/blob/master/TDDualControl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evq_IBs_gJ0R",
        "colab_type": "code",
        "outputId": "7ff0cace-0900-4d8c-a981-f8d4f5a1756e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "! git clone https://github.com/3ammor/Weights-Initializer-pytorch.git\n",
        "import sys\n",
        "\n",
        "sys.path\n",
        "sys.path.append('/content/Weights-Initializer-pytorch')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import PIL.Image\n",
        "from weight_initializer import Initializer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Weights-Initializer-pytorch'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPALIG6JVd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dynamics:\n",
        "  \n",
        "    def __init__(self, environment, g = 1., noise=0.05, lam=0.01, control=None):\n",
        "        self.environment = environment\n",
        "        self.g = g\n",
        "        self.noise = noise\n",
        "        self.xt = []\n",
        "        self.yt = []\n",
        "        self.control = control\n",
        "        self.lam = lam\n",
        "        self.cost = 0.\n",
        "        \n",
        "    def compute_force(self, r, t):\n",
        "        upscaled_h_cells = torch.nn.functional.interpolate(environment.h_cells, scale_factor=environment.scale,  mode=\"bilinear\", align_corners=True)\n",
        "        _, Gx, Gy = environment.extrapolate(r[:,0], r[:,1], upscaled_h_cells, \n",
        "                                            activation=lambda x: x, \n",
        "                                            derivative=True,\n",
        "                                            d_activation=lambda x: x)\n",
        "        if self.control is not None:\n",
        "          Ux = environment.extrapolate(r[:,0], r[:,1], self.control[t][0], \n",
        "                                       activation=lambda x: x, \n",
        "                                       derivative=False,\n",
        "                                       std=.5, \n",
        "                                       normalized=True)\n",
        "          Uy = environment.extrapolate(r[:,0], r[:,1], self.control[t][1], \n",
        "                                       activation=lambda x: x, \n",
        "                                       derivative=False,\n",
        "                                       std=.5, \n",
        "                                       normalized=True)\n",
        "          control_force = torch.cat((Ux, Uy), 1)\n",
        "        else:\n",
        "          control_force = 0.\n",
        "        grad = torch.cat((Gx.unsqueeze(1), Gy.unsqueeze(1)), 1)\n",
        "        env_x_repulsion = 3*torch.sigmoid(-10*r[:,0]) - 3*torch.sigmoid(-10*(environment.resolution - r[:,0]))\n",
        "        env_y_repulsion = 3*torch.sigmoid(-10*r[:,1]) - 3*torch.sigmoid(-10*(environment.resolution - r[:,1]))\n",
        "        repulsion_force = torch.stack((env_x_repulsion, env_y_repulsion),1)\n",
        "        F = (self.g * grad + control_force + repulsion_force)\n",
        "        if self.control is not None:\n",
        "          control_cost = self.lam*torch.sum(control_force**2,1)\n",
        "        else:\n",
        "          control_cost = 0.\n",
        "        return F, control_cost\n",
        "\n",
        "    def compute_reward(self, r):\n",
        "        R = environment.extrapolate(r[:,0], r[:,1], environment.r, \n",
        "                                    activation=lambda x: x, \n",
        "                                    derivative=False,\n",
        "                                    std=.5, \n",
        "                                    normalized=True)\n",
        "        return torch.sum(R, 1) \n",
        "\n",
        "    def integrate(self, r, dt, N): #Midpoint integration\n",
        "        num_samples = self.environment.num_samples\n",
        "        for n in range(N):\n",
        "            F0, control_cost0 = self.compute_force(r, n)\n",
        "            F, control_cost = self.compute_force(r + 0.5*dt*F0, n)\n",
        "            r = r + (F * dt + torch.normal(0., self.noise, (self.environment.num_samples,2)) * dt**(1/2.))\n",
        "            self.xt += [r.detach().numpy()[:, 0]]\n",
        "            self.yt += [r.detach().numpy()[:, 1]]\n",
        "            self.cost +=  0.5*(control_cost0 + control_cost)\n",
        "        self.cost += - 0.0001*self.compute_reward(r)\n",
        "        return r\n",
        "\n",
        "    def sample(self, dt, num_iter):\n",
        "        r0 = torch.empty(self.environment.num_samples, 2).uniform_(10, self.environment.resolution-10)\n",
        "        r = self.integrate(r0, dt, num_iter)\n",
        "        return r\n",
        "\n",
        "    def reset(self):\n",
        "        self.xt = []\n",
        "        self.yt = []\n",
        "        self.cost = 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRAwzMN7fX12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logit(x):\n",
        "  return np.log(x) + np.log(1 - x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y14Qs1lAgQh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussianEnvironment:\n",
        "\n",
        "    def __init__(self, resolution, std, num_samples, scale = 5):\n",
        "        if resolution % scale != 0:\n",
        "          raise(ValueError)(\"The resulition should have {} as a factor\".format(scale))\n",
        "        latent_resolution   = int(resolution/scale)\n",
        "        self.distribution_mean = torch.zeros([num_samples, 1, latent_resolution, latent_resolution])\n",
        "        self.distribution_std = torch.ones([num_samples, 1, latent_resolution, latent_resolution])\n",
        "        self.r_distribution_logits = logit(3./(latent_resolution*latent_resolution))*torch.ones([num_samples, latent_resolution*latent_resolution])\n",
        "        self.num_samples = num_samples\n",
        "        self.resolution   = resolution\n",
        "        self.latent_resolution   = latent_resolution\n",
        "        self.scale = scale\n",
        "        self.std          = std\n",
        "        self.environment_hardness = 0.01\n",
        "        self.reward_hardness = 0.01\n",
        "        self.is_generated = False\n",
        "        self.colors = [(torch.tensor([0., 0., 1.]).unsqueeze(1).unsqueeze(2).expand(1,3,resolution, resolution), 0, 0.2),\n",
        "                       (torch.tensor([0., 1., 0.]).unsqueeze(1).unsqueeze(2).expand(1,3,resolution, resolution), 0.2, 0.4),\n",
        "                       (torch.tensor([0.58824, 0.29412, 0]).unsqueeze(1).unsqueeze(2).expand(1,3,resolution, resolution), 0.4, 0.6),\n",
        "                       (torch.tensor([0.5, 0.5, 0.5]).unsqueeze(1).unsqueeze(2).expand(1,3,resolution, resolution), 0.6, 0.8),\n",
        "                       (torch.tensor([1., 1., 1.]).unsqueeze(1).unsqueeze(2).expand(1,3,resolution, resolution), 0.6, 0.8)]\n",
        "        self.halfsize     = None\n",
        "        self.kernel       = None\n",
        "        self.set_kernel()\n",
        "        self.c   = None\n",
        "        self.h   = None\n",
        "        self.dxh = None\n",
        "        self.dyx = None\n",
        "\n",
        "    def visibility_map(self, x0, y0, v0, k0):\n",
        "        arange        = torch.arange(0., self.resolution).float()\n",
        "        x, y          = torch.meshgrid([arange, arange])\n",
        "        h = self.extrapolate(x0, y0, self.h, \n",
        "                             activation=lambda x: x, \n",
        "                             derivative=False,\n",
        "                             normalized=True) \n",
        "        x0 = x0.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        y0 = y0.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        h = h.unsqueeze(2).unsqueeze(3).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        \n",
        "        d_map = torch.sqrt(((x0 - x) ** 2 + (y0 - y) ** 2))\n",
        "        visibility_mask = 1./(1. + F.relu(d_map - h*k0 + 1)**2)\n",
        "        hard_mask = 1. - torch.sigmoid(10000*(d_map - h*k0 + 1))\n",
        "        likelihood_variance = v0 + F.relu(d_map - h*k0 + 1)**3\n",
        "        return likelihood_variance, visibility_mask, hard_mask\n",
        "        \n",
        "    def env_bayesian_update(self, inference_net, x0, y0, v0 = 0.00001, k0 = 30., data=None):\n",
        "        prior_mean = self.distribution_mean\n",
        "        prior_std = self.distribution_std\n",
        "\n",
        "        likelihood_variance, visibility_mask, hard_mask = self.visibility_map(x0, y0, v0, k0)\n",
        "        \n",
        "        if data is None:\n",
        "           mean = self.h\n",
        "           distribution = torch.distributions.normal.Normal(mean,torch.sqrt(likelihood_variance))\n",
        "           sample = distribution.rsample()\n",
        "           data = hard_mask*sample \n",
        "\n",
        "        posterior_mean, posterior_var = inference_net.get_posterior_parameters(data, likelihood_variance, prior_mean, prior_std)\n",
        "\n",
        "        self.distribution_mean = posterior_mean\n",
        "        self.distribution_std = torch.sqrt(posterior_var)\n",
        "\n",
        "        variational_loss1 = inference_net.neg_ELBO_loss(data, prior_mean, prior_std, self, likelihood_variance,hard_mask)\n",
        "        latent = self.h_cells\n",
        "        variational_loss2 = inference_net.FAVI_loss(data, latent, prior_mean, prior_std, likelihood_variance)\n",
        "        return variational_loss1 + variational_loss2\n",
        "\n",
        "    def rew_bayesian_update(self, inference_net, x0, y0, v0 = 0.001, k0 = 20., data=None):\n",
        "        prior_logits = self.r_distribution_logits\n",
        "        \n",
        "        likelihood_variance, visibility_mask, hard_mask = self.visibility_map(x0, y0, v0, k0)\n",
        "        \n",
        "        if data is None:\n",
        "           mean = self.r\n",
        "           distribution = torch.distributions.normal.Normal(mean,torch.sqrt(likelihood_variance))\n",
        "           sample = distribution.rsample()\n",
        "           data = hard_mask*sample \n",
        "\n",
        "        posterior_logits = inference_net.get_posterior_parameters(data, likelihood_variance, prior_logits, hard_mask)\n",
        "        self.r_distribution_logits = posterior_logits\n",
        "\n",
        "        #variational_loss = inference_net.neg_ELBO_loss(data, prior_logits, self, likelihood_variance) \n",
        "        latent = self.r_cells\n",
        "        variational_loss = inference_net.FAVI_loss(data, latent, prior_logits, likelihood_variance, hard_mask)\n",
        "        return variational_loss\n",
        "\n",
        "    def dsigmoidd(self, x):\n",
        "        sigmoid = torch.sigmoid(x);\n",
        "        return sigmoid * (1 - sigmoid)\n",
        "\n",
        "    def get_statistics(self):\n",
        "        return self.distribution_mean, self.distribution_std, self.r_distribution_logits\n",
        "\n",
        "    def filter_environment(self, cells):\n",
        "        upscaled_cells = torch.nn.functional.interpolate(cells, scale_factor=self.scale,  mode=\"bilinear\", align_corners=True)\n",
        "        pre_map = torch.nn.functional.conv2d(upscaled_cells, \n",
        "                                             self.kernel.unsqueeze(0).unsqueeze(0), padding = self.halfsize)\n",
        "        env_map = torch.sigmoid(self.environment_hardness * pre_map)\n",
        "\n",
        "        dxh = torch.nn.functional.conv2d(upscaled_cells, \n",
        "                                         self.dxkernel.unsqueeze(0).unsqueeze(0), padding = self.halfsize)\n",
        "        dyh = torch.nn.functional.conv2d(upscaled_cells, \n",
        "                                         self.dykernel.unsqueeze(0).unsqueeze(0), padding = self.halfsize)\n",
        "\n",
        "        dxh = dxh * self.environment_hardness * self.dsigmoidd(self.environment_hardness * pre_map)\n",
        "        dyh = dyh * self.environment_hardness * self.dsigmoidd(self.environment_hardness * pre_map)\n",
        "        return env_map, dxh, dyh\n",
        "\n",
        "    def filter_reward(self, r_cells):\n",
        "        upscaled_r_cells = torch.nn.functional.interpolate(r_cells.view((self.num_samples,1,self.latent_resolution, self.latent_resolution)), \n",
        "                                                           scale_factor=self.scale,  mode=\"bilinear\", align_corners=True)\n",
        "        reward = (0.1/3)*torch.nn.functional.conv2d(upscaled_r_cells, \n",
        "                                                    self.kernel.unsqueeze(0).unsqueeze(0), padding = self.halfsize)\n",
        "        return reward\n",
        "\n",
        "    def generate(self):\n",
        "        mean = self.distribution_mean\n",
        "        std = self.distribution_std\n",
        "        distribution = torch.distributions.normal.Normal(mean, \n",
        "                                                         std)\n",
        "        cells = distribution.rsample()\n",
        "        \n",
        "        r_logits = self.r_distribution_logits\n",
        "        r_distribution = torch.distributions.bernoulli.Bernoulli(logits=r_logits)\n",
        "        r_cells = r_distribution.sample()\n",
        "        \n",
        "        env_map, dxh, dyh = self.filter_environment(cells)\n",
        "        reward = self.filter_reward(r_cells)\n",
        "\n",
        "        self.c = self.paint(env_map)\n",
        "        self.h_cells = cells\n",
        "        self.h = env_map\n",
        "        self.r = reward\n",
        "        self.r_cells = r_cells\n",
        "        self.dxh = dxh\n",
        "        self.dyh = dyh\n",
        "        self.is_generated = True\n",
        "    \n",
        "    def set_kernel(self):\n",
        "        self.halfsize = 4*int(np.ceil(2 * self.std))\n",
        "        arange        = torch.arange(-self.halfsize, self.halfsize + 1).float()\n",
        "        x, y          = torch.meshgrid([arange, arange])\n",
        "        self.kernel   = torch.exp(-(x ** 2 + y ** 2) / (2 * self.std ** 2))\n",
        "        self.dxkernel = -self.kernel.detach() * x / self.std **2\n",
        "        self.dykernel = -self.kernel.detach() * y / self.std **2\n",
        "\n",
        "    def extrapolate(self, x0, y0, image, activation, derivative=False, d_activation = None, std=None, normalized=False):\n",
        "        if std is None: #\n",
        "          std = self.std\n",
        "        arange        = torch.arange(0., self.resolution).float()\n",
        "        x, y          = torch.meshgrid([arange, arange])\n",
        "        x = x.unsqueeze(0).unsqueeze(0).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        y = y.unsqueeze(0).unsqueeze(0).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        x0 = x0.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        y0 = y0.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        \n",
        "        weights = torch.exp(-((x0 - x) ** 2 + (y0 - y) ** 2) / (2 * std ** 2))\n",
        "\n",
        "        if derivative:\n",
        "          dx_weights = -(x - x0)*weights / self.std **2\n",
        "          dy_weights = -(y - y0)*weights / self.std **2\n",
        "\n",
        "        if normalized:\n",
        "          weights = weights/torch.sum(weights, (1,2,3), keepdim=True).expand(self.num_samples,1,self.resolution,self.resolution)\n",
        "        extr = torch.sum(image * weights, (1,2,3))\n",
        "\n",
        "        if derivative:\n",
        "          dx_extr = d_activation(extr)*torch.sum(image * dx_weights, (1,2,3))\n",
        "          dy_extr = d_activation(extr)*torch.sum(image * dy_weights, (1,2,3))\n",
        "          return activation(extr), dx_extr, dy_extr\n",
        "        else:\n",
        "          extr = activation(torch.sum(image * weights, (2,3)))\n",
        "          return activation(extr)\n",
        "\n",
        "    def soft_indicator(self, lower, upper, soft):\n",
        "        indicator = lambda height: torch.sigmoid(soft * (height - lower)) * (1 - torch.sigmoid(soft * (height - upper)))\n",
        "        return indicator\n",
        "\n",
        "    def paint(self, x):\n",
        "        return sum([color.expand(self.num_samples,3,self.resolution,self.resolution) * self.soft_indicator(lower, upper, 10.)(x) for color, lower, upper in self.colors])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um_qwlrKaq2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HJB(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, image_size, x_force, y_force, noise_map, reward, lam, dt, intermediate_reward=False):\n",
        "        super(HJB, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.x_force = x_force\n",
        "        self.y_force = y_force\n",
        "        self.noise_map = noise_map\n",
        "        self.reward = reward\n",
        "        self.lam = lam\n",
        "        self.dt = dt\n",
        "        self.kx, self.ky, self.k_laplace = self._get_derivative_filters()\n",
        "        self.intermediate_reward = intermediate_reward\n",
        "        #self.kx_minus, self.kx_plus, self.ky_minus, self.ky_plus = self._get_derivative_filters()\n",
        "\n",
        "    def _get_derivative_filters(self): #Upwind method\n",
        "        ky = torch.tensor([[1., 2. , 1.], [0., 0., 0.], [-1., -2. , -1.]])/4.\n",
        "        ky = ky.expand(1,1,3,3)\n",
        "        kx = torch.transpose(ky, 3, 2)\n",
        "        k_laplace = torch.tensor([[1., 1. , 1.], [1., -8. , 1.], [1., 1. , 1.]])\n",
        "        k_laplace = k_laplace.expand(1,1,3,3)\n",
        "        return kx, ky, k_laplace\n",
        "\n",
        "    def backward_update(self, V, control=False):\n",
        "       Vpad = torch.nn.functional.pad(V, (1,1,1,1), \"reflect\")\n",
        "       dVx = torch.nn.functional.conv2d(Vpad, self.kx, padding = 0)\n",
        "       dVy = torch.nn.functional.conv2d(Vpad, self.ky, padding = 0)\n",
        "       LV = torch.nn.functional.conv2d(Vpad, self.k_laplace, padding = 0)\n",
        "       if self.intermediate_reward:\n",
        "          r = self.reward\n",
        "       else:\n",
        "          r = 0.\n",
        "       update = (-r - dVx**2/(2*self.lam) - dVy**2/(2*self.lam) + self.x_force * dVx + self.y_force * dVy + self.noise_map**2*LV)\n",
        "       if control:\n",
        "          Ux = -(1/self.lam)*dVx \n",
        "          Uy = -(1/self.lam)*dVy\n",
        "          return update, Ux, Uy\n",
        "       else:\n",
        "          return update\n",
        "\n",
        "    def backward_step(self, V):\n",
        "        update, Ux, Uy = self.backward_update(V, control=True)\n",
        "        Vprev = V + self.dt*update\n",
        "        return Vprev, Ux, Uy\n",
        "\n",
        "    def RK_backward_step(self, V):\n",
        "        k1, Ux, Uy = self.backward_update(V, control=True)\n",
        "        k1 *= self.dt\n",
        "        k2 = self.dt*self.backward_update(V + k1/2)\n",
        "        k3 = self.dt*self.backward_update(V + k2/2)\n",
        "        k4 = self.dt*self.backward_update(V + k3)\n",
        "        return V + (k1 + 2*k2 + 2*k3 + k4)/6., Ux, Uy \n",
        "\n",
        "    def compute_value(self, N, RK = False, plot=False):\n",
        "        Vn = -self.reward \n",
        "        V_list = [-Vn]\n",
        "        U_list = [None]\n",
        "        for n in reversed(range(N)):\n",
        "         if n % 20 == 0:\n",
        "            if plot:\n",
        "              x,y = (np.arange(0, resolution), np.arange(0, resolution))\n",
        "              plt.imshow(Vn[0,:,:,:].detach().numpy().squeeze(), extent = [0, resolution, 0, resolution], origin=\"lower\")\n",
        "              plt.quiver(x, y, environment.dyh[0,:,:,:].detach().numpy().squeeze(), environment.dxh[0,:,:,:].detach().numpy().squeeze())\n",
        "              #plt.quiver(x, y, Ux[0,:,:,:].detach().numpy().squeeze(), Uy[0,:,:,:].numpy().squeeze(), color=\"red\")\n",
        "              fig = plt.gcf()\n",
        "              fig.set_size_inches(18.5, 18.5)\n",
        "              plt.show()\n",
        "         if not RK:\n",
        "           Vn, Ux, Uy = self.backward_step(Vn)\n",
        "         else:\n",
        "           Vn, Ux, Uy = self.RK_backward_step(Vn) \n",
        "         V_list.append(-Vn)\n",
        "         U_list.append((-Uy, -Ux)) #TODO: flipped/sign flipped\n",
        "        return list(reversed(V_list)), list(reversed(U_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOy5u2IwSnqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnvInferenceNet(nn.Module):\n",
        "\n",
        "    def __init__(self, gain, h_size=30, k_size=3, var_k_size=3, latent_resolution = 8, scale_factor = 5):\n",
        "        super(EnvInferenceNet, self).__init__()\n",
        "\n",
        "        self.conv_in = nn.Conv2d(h_size, h_size, k_size, padding=0) #Input: h_mean, h_std, r_mean, r_std times h_size\n",
        "        self.out =  nn.Linear(latent_resolution*latent_resolution*h_size*scale_factor**2, latent_resolution*latent_resolution)\n",
        "\n",
        "        self.var_l1 = nn.Conv2d(1, h_size, 1, padding=0, bias=False)\n",
        "        self.var_out = nn.Conv2d(h_size, 1 , 1, padding=0, bias=False)\n",
        "\n",
        "        # Parameters\n",
        "        self.h_size = h_size\n",
        "        self.k_size = k_size\n",
        "        self.k_pad = int((k_size - 1)/2)\n",
        "        self.var_k_pad = int((var_k_size - 1)/2)\n",
        "        self.latent_resolution = latent_resolution\n",
        "        self.scale_factor = scale_factor\n",
        "        self.gain = gain\n",
        "\n",
        "    def forward(self,  data, likelihood_var):\n",
        "\n",
        "        activation = lambda x: torch.relu(x)\n",
        "        b_size = data.shape[0]\n",
        "\n",
        "        x = data.repeat(1,self.h_size,1,1)\n",
        "        x_pad = torch.nn.functional.pad(x, (self.k_pad,self.k_pad,self.k_pad,self.k_pad), \"reflect\")\n",
        "        h = activation(self.conv_in(x_pad)).view(b_size, self.h_size*self.latent_resolution*self.latent_resolution*self.scale_factor**2)\n",
        "        latent_data = self.out(h)\n",
        "        latent_data = latent_data.view(b_size,1,self.latent_resolution,self.latent_resolution)\n",
        "        \n",
        "        x = F.interpolate(likelihood_var, scale_factor=1/self.scale_factor,  mode=\"bilinear\", align_corners=True)\n",
        "        x = activation(self.var_l1(x))\n",
        "        x = self.var_out(x)**2\n",
        "\n",
        "        return self.gain*latent_data, x\n",
        "\n",
        "    def get_posterior_parameters(self, data, likelihood_var, prior_mean, prior_std):\n",
        "       latent_data, latent_variance = self(data, likelihood_var)\n",
        "       posterior_var = 1/(1/prior_std**2 + 1/latent_variance)\n",
        "       posterior_mean = (prior_mean/prior_std**2 + latent_data/latent_variance)*posterior_var\n",
        "       return posterior_mean, posterior_var\n",
        "\n",
        "    def neg_ELBO_loss(self, data, prior_mean, prior_std, environment, lk_variance, mask):\n",
        "       prior_distribution = torch.distributions.normal.Normal(prior_mean, prior_std)\n",
        "       posterior_mean, posterior_var =  self.get_posterior_parameters(data, lk_variance, prior_mean, prior_std)\n",
        "       post_distribution = torch.distributions.normal.Normal(posterior_mean,torch.sqrt(posterior_var))\n",
        "\n",
        "       posterior_sample = post_distribution.rsample()\n",
        "       lik_filter = lambda x: environment.filter_environment(x)[0]\n",
        "       avg_log_lik = torch.mean(-0.5*mask*(data - lik_filter(posterior_sample))**2/lk_variance)\n",
        "\n",
        "       KL_regularization = torch.distributions.kl.kl_divergence(post_distribution, prior_distribution)\n",
        "       return torch.mean(-avg_log_lik + KL_regularization)\n",
        "\n",
        "    def FAVI_loss(self, data, latent, prior_mean, prior_std, lk_variance):\n",
        "       posterior_mean, posterior_var =  self.get_posterior_parameters(data, lk_variance, prior_mean, prior_std)\n",
        "       loss =  torch.mean(0.5*(latent - posterior_mean)**2/posterior_var + 0.5*torch.log(2*np.pi*posterior_var))\n",
        "       return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPMFvNboCy4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RewInferenceNet(nn.Module):\n",
        "\n",
        "    def __init__(self, gain, h_size=60, k_size=5, latent_resolution = 8, scale_factor = 5):\n",
        "        super(RewInferenceNet, self).__init__()\n",
        "\n",
        "        self.l = nn.Linear(latent_resolution*latent_resolution*scale_factor**2, latent_resolution*latent_resolution)\n",
        "\n",
        "        #self.var_l1 = nn.Conv2d(1, h_size, 1, padding=0, bias=False)\n",
        "        #self.var_out = nn.Conv2d(h_size, 1 , 1, padding=0, bias=False)\n",
        "\n",
        "        # Parameters\n",
        "        self.h_size = h_size\n",
        "        self.k_size = k_size\n",
        "        self.k_pad = int((k_size - 1)/2)\n",
        "        self.latent_resolution = latent_resolution\n",
        "        self.scale_factor = scale_factor\n",
        "        self.gain = gain\n",
        "\n",
        "    def forward(self, data, likelihood_var, hard_mask):\n",
        "        b_size = data.shape[0]\n",
        "        mask = F.interpolate(hard_mask, scale_factor=1/self.scale_factor,  mode=\"bilinear\", align_corners=True).view((b_size,self.latent_resolution*self.latent_resolution))\n",
        "        x = mask*(0.1*F.softplus(self.l(data.view(b_size, self.latent_resolution*self.latent_resolution*self.scale_factor**2))) - 2.)\n",
        "        return x\n",
        "\n",
        "    def get_posterior_parameters(self, data, likelihood_var, prior_logits, hard_mask):\n",
        "       latent_logits = self(data, likelihood_var, hard_mask)\n",
        "       posterior_logits = prior_logits + latent_logits\n",
        "       return posterior_logits\n",
        "\n",
        "    def neg_ELBO_loss(self, data, prior_logits, environment, lk_variance):\n",
        "       prior_distribution = torch.distributions.categorical.Categorical(logits=prior_logits)\n",
        "       posterior_logits =  self.get_posterior_parameters(data, lk_variance, prior_logits)\n",
        "       post_distribution = torch.distributions.categorical.Categorical(logits=posterior_logits)\n",
        "\n",
        "       enumeration = post_distribution.enumerate_support(expand=False)\n",
        "       log_probs = post_distribution.log_prob(enumeration).transpose(1,0)\n",
        "       probs = torch.exp(log_probs).unsqueeze(2).unsqueeze(3)\n",
        "       log_lk = torch.sum(-0.5*(data - environment.filter_reward(enumeration[:,0]).transpose(1,0))**2/lk_variance, (2,3))\n",
        "       avg_log_lik = torch.mean(probs*log_lk.detach())\n",
        "#\n",
        "       KL_regularization = torch.distributions.kl.kl_divergence(post_distribution, prior_distribution)\n",
        "\n",
        "       return torch.mean(-avg_log_lik + KL_regularization)\n",
        "\n",
        "    def FAVI_loss(self, data, latent, prior_logits, lk_variance, hard_mask):\n",
        "       b_size = data.shape[0]\n",
        "       weights = F.interpolate(hard_mask, scale_factor=1/self.scale_factor,  mode=\"bilinear\", align_corners=True).view((b_size,self.latent_resolution*self.latent_resolution))\n",
        "       loss_fn = torch.nn.BCEWithLogitsLoss(weight=weights.detach())\n",
        "       posterior_logits = self.get_posterior_parameters(data, lk_variance, prior_logits, hard_mask)\n",
        "       loss =  loss_fn(posterior_logits, latent.detach())\n",
        "       \n",
        "       if False and iteration % 10 == 0:\n",
        "          plot_map(data)\n",
        "          mean_r_cells = torch.sigmoid(torch.nn.functional.interpolate(posterior_logits.view((b_size,1,self.latent_resolution, self.latent_resolution)), \n",
        "                                                                       scale_factor=self.scale_factor,  mode=\"bilinear\", align_corners=True))\n",
        "          r_mean = (0.1/3)*torch.nn.functional.conv2d(mean_r_cells, \n",
        "                                                      environment.kernel.unsqueeze(0).unsqueeze(0), padding = environment.halfsize)\n",
        "          r_var = r_mean*(1 - r_mean)\n",
        "          plot_map(r_mean)\n",
        "          plot_map(r_var)\n",
        "\n",
        "       return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkjtWWkL_rV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Policy network TODO: Work in progress\n",
        "\n",
        "class ValueNet(nn.Module):\n",
        "    def __init__(self, environment, smoothing_std=2, h_size=40, k_size=1):\n",
        "        super(ValueNet, self).__init__()\n",
        "        \n",
        "        self.conv_in = nn.Conv2d(3, h_size, k_size, padding=0, bias=False) \n",
        "        self.out = nn.Linear(environment.latent_resolution*environment.latent_resolution*h_size,\n",
        "                             environment.latent_resolution*environment.latent_resolution, bias=False) \n",
        "        self.conv_out = nn.Conv2d(h_size, 1, k_size, padding=0, bias=False)\n",
        "        \n",
        "        # Smoothing layer\n",
        "        self.smoothing_std = smoothing_std\n",
        "\n",
        "        # Parameters\n",
        "        self.h_size = h_size\n",
        "        self.k_size = k_size\n",
        "        self.k_pad = int((k_size - 1)/2)\n",
        "        self.halfsize = 4*int(np.ceil(2 * smoothing_std))\n",
        "        arange        = torch.arange(-self.halfsize, self.halfsize + 1).float()\n",
        "        x, y          = torch.meshgrid([arange, arange])\n",
        "        self.smoothing_ker = torch.exp(-(x ** 2 + y ** 2) / (2 * smoothing_std ** 2))\n",
        "        self.environment = environment\n",
        "        self.V_trace = None\n",
        "\n",
        "    def forward(self,  h_mean, h_std, r_logits, N, g, dt, exploit=False):\n",
        "\n",
        "        activation = lambda x: F.softplus(x)\n",
        "\n",
        "        predicted_reward = 0.1*environment.filter_reward(torch.sigmoid(r_logits))\n",
        "\n",
        "        x = torch.cat((h_mean, \n",
        "                       h_std, \n",
        "                       r_logits.view((environment.num_samples, \n",
        "                                      1, \n",
        "                                      environment.latent_resolution, \n",
        "                                      environment.latent_resolution))), \n",
        "                      1)\n",
        "        x = activation(self.conv_in(x))\n",
        "        y = x.view((environment.num_samples, self.h_size*environment.latent_resolution**2))\n",
        "        z = self.conv_out(x)\n",
        "        x = z #+ 0.1*self.out(y).view((environment.num_samples, 1, environment.latent_resolution, environment.latent_resolution))\n",
        "        x = F.interpolate(x, scale_factor=environment.scale,  \n",
        "                          mode=\"bilinear\", align_corners=True)\n",
        "        x_pad = torch.nn.functional.pad(x, (self.halfsize,self.halfsize,self.halfsize,self.halfsize), \"reflect\")\n",
        "        output = torch.nn.functional.conv2d(x_pad.view(environment.num_samples, \n",
        "                                                       1, \n",
        "                                                       x_pad.shape[2], \n",
        "                                                       x_pad.shape[3]), self.smoothing_ker.unsqueeze(0).unsqueeze(0)).view(environment.num_samples, \n",
        "                                                                                                                           1, \n",
        "                                                                                                                           environment.resolution, \n",
        "                                                                                                                           environment.resolution)\n",
        "        value = 0.01*F.softplus(output)\n",
        "\n",
        "        if exploit is False:\n",
        "            hjb_input = value\n",
        "        else:\n",
        "            hjb_input = predicted_reward\n",
        "\n",
        "        hjb = HJB(image_size=environment.resolution, \n",
        "                  x_force= -g*environment.dyh, #TODO: this should be changed\n",
        "                  y_force= -g*environment.dxh, #TODO: this should be changed\n",
        "                  noise_map= 0.25, #TODO: this should be changed\n",
        "                  reward=hjb_input, \n",
        "                  lam= 0.02, \n",
        "                  dt=dt)\n",
        "        _, Ulist = hjb.compute_value(N, RK=True)\n",
        "        return value, Ulist\n",
        "\n",
        "    def TDloss(self, reward, value, future_value, kernel, gamma=0.9):\n",
        "        reward = reward.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
        "        future_value = future_value.unsqueeze(2).unsqueeze(3)\n",
        "        #\n",
        "        TD_target = (reward + gamma*future_value).detach()\n",
        "        loss = torch.mean(kernel*(value - TD_target)**2)\n",
        "        return loss\n",
        "\n",
        "    def TD_lambda_loss(self, reward, value, future_value, kernel, step, gamma=0.95, lam = 0.2):\n",
        "        if step == 0:\n",
        "          self.V_trace = 0.\n",
        "        else:\n",
        "          self.V_trace = gamma*lam*self.V_trace + value\n",
        "        future_value = future_value.unsqueeze(2).unsqueeze(3)\n",
        "        loss = torch.mean(kernel*(reward + gamma*future_value.detach() - value).detach()*V_trace)\n",
        "        return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vkUz0RCvgA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_trajectories(Ulist, environment, dynamics, value):\n",
        "    x0_range = [20., 40.]\n",
        "    y0_range = [20., 40.]\n",
        "\n",
        "    _, _, r_logits = environment.get_statistics()\n",
        "    r_map = environment.filter_reward(torch.sigmoid(r_logits))\n",
        "\n",
        "    x,y = (np.arange(0, environment.resolution), np.arange(0, environment.resolution))\n",
        "    #plt.imshow(environment.h[0,0,:,:].detach().numpy().squeeze(), extent = [0, environment.resolution, 0, environment.resolution], origin=\"lower\")\n",
        "    #plt.contour(x, y, environment.h[0,0,:,:].detach().numpy().squeeze(), colors='red')\n",
        "    plt.imshow(r_map[0,0,:,:].detach().numpy().squeeze(), extent = [0, environment.resolution, 0, environment.resolution], origin=\"lower\")\n",
        "    plt.quiver(x, y, environment.dyh[0,0,:,:].detach().numpy().squeeze(), environment.dxh[0,:,:,:].detach().numpy().squeeze())\n",
        "    plt.plot(np.array(dynamics.yt)[:,0], np.array(dynamics.xt)[:,0], linewidth=4, color = \"red\")\n",
        "    plt.plot(np.array(dynamics.yt)[0,0], np.array(dynamics.xt)[0,0], \"xb\")\n",
        "    plt.colorbar()\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(18.5, 18.5)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX6j35Ed4VDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_map(mp, norm=False, lim=1.):\n",
        "    x0_range = [20., 40.]\n",
        "    y0_range = [20., 40.]\n",
        "\n",
        "    x,y = (np.arange(0, environment.resolution), np.arange(0, environment.resolution))\n",
        "    plt.imshow(mp[0,0,:,:].detach().numpy().squeeze(), extent = [0, environment.resolution, 0, environment.resolution], origin=\"lower\")\n",
        "    plt.colorbar()\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(18.5, 18.5)\n",
        "    #plt.clim(0,1.)\n",
        "    if norm:\n",
        "      plt.clim(0,1.)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utes6F7dk4M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_network(net, name):\n",
        "  pickle.dump(net, open( \"{}.p\".format(name), \"wb\" ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5cVhh0nlLFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_network(name):\n",
        "  return pickle.load( open( \"{}.p\".format(name), \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amrEySpd6qSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "N_iters = 2000 \n",
        "RL_batch_size = 3\n",
        "VI_batch_size = 20\n",
        "N_steps = 5\n",
        "N_intergration_steps = 400 #200\n",
        "N_VI_iterations = 400\n",
        "\n",
        "resolution = 40 #40\n",
        "scale = 8 #5\n",
        "std = 7.5\n",
        "g = 0.0005 #0.005\n",
        "noise = 0.3\n",
        "dt = 0.1\n",
        "\n",
        "environment = GaussianEnvironment(resolution=resolution, std=std, num_samples=VI_batch_size, scale=scale)\n",
        "net = ValueNet(environment) #TODO: Multiple networks\n",
        "#Initializer.initialize(model=net, initialization=nn.init.xavier_uniform, gain=nn.init.calculate_gain('relu'))\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.00001) \n",
        "\n",
        "env_inference_net = EnvInferenceNet(gain=1., scale_factor = scale, latent_resolution = int(resolution/scale)) #TODO: Multiple networks\n",
        "#Initializer.initialize(model=env_inference_net, initialization=nn.init.xavier_uniform, gain=nn.init.calculate_gain('relu'))\n",
        "env_VI_optimizer = optim.Adam(env_inference_net.parameters(), lr=0.00001) \n",
        "\n",
        "reward_inference_net = RewInferenceNet(gain=1., scale_factor = scale, latent_resolution = int(resolution/scale)) #TODO: Multiple networks\n",
        "#Initializer.initialize(model=reward_inference_net, initialization=nn.init.xavier_uniform, gain=nn.init.calculate_gain('relu'))\n",
        "reward_VI_optimizer = optim.Adam(reward_inference_net.parameters(), lr=0.0001) \n",
        "\n",
        "loss_list = []\n",
        "env_VI_loss_list = []\n",
        "reward_VI_loss_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUvgwW1La3Om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "457ff83d-4c34-428c-fa94-b1fe54eab2e3"
      },
      "source": [
        "load_value_net = False\n",
        "try:\n",
        "  env_inference_net = load_network(\"env_net\")\n",
        "  reward_inference_net = load_network(\"reward_net\")\n",
        "  print(\"Loading inference networks\")\n",
        "  N_VI_itr = 0\n",
        "except:\n",
        "  print(\"Training inference networks\")\n",
        "  N_VI_itr = N_VI_iterations\n",
        "\n",
        "if load_value_net:\n",
        "  try:\n",
        "    net = load_network(\"value_net\")\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
        "    print(\"Loading value networks\")\n",
        "  except:\n",
        "    print(\"Training value network\")\n",
        "\n",
        "for iteration in range(N_iters):\n",
        "   if iteration > N_VI_itr:\n",
        "      batch_size = RL_batch_size\n",
        "   else:\n",
        "      batch_size = VI_batch_size\n",
        "   print(\"Iteration: {}\".format(iteration))\n",
        "   environment = GaussianEnvironment(resolution=resolution, std=std, num_samples=batch_size, scale=scale)\n",
        "   dynamics = Dynamics(environment, g=g, noise=noise, lam=0.0000)\n",
        "   environment.generate()\n",
        "   r = dynamics.sample(dt, 1)\n",
        "   if iteration > N_VI_itr:\n",
        "      environment.env_bayesian_update(env_inference_net, r[:,0], r[:,1])\n",
        "      environment.generate() \n",
        "   total_loss = 0.\n",
        "   total_reward = 0.\n",
        "   total_env_VI_loss = 0.\n",
        "   total_reward_VI_loss = 0.\n",
        "   reward = torch.zeros((batch_size,))\n",
        "   for step in range(N_steps):\n",
        "      print(\"Step: {}\".format(step))\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      env_VI_optimizer.zero_grad()\n",
        "      env_VI_optimizer.zero_grad()\n",
        "\n",
        "      ## Control ##\n",
        "      if step == N_steps - 1:\n",
        "        exploit = True\n",
        "      else:\n",
        "        exploit = False\n",
        "      if iteration > N_VI_itr:\n",
        "        h_mean, h_std, r_logits = environment.get_statistics()\n",
        "        value, Ulist = net.forward(h_mean, \n",
        "                                   h_std, \n",
        "                                   r_logits, \n",
        "                                   N_intergration_steps, g, dt, exploit=exploit)\n",
        "        dynamics.control = Ulist\n",
        "        print(value.max())\n",
        "\n",
        "      old_r = r\n",
        "\n",
        "      if iteration > N_VI_itr:\n",
        "        r = dynamics.integrate(r, dt, N_intergration_steps).detach()\n",
        "      else:\n",
        "        r = dynamics.sample(dt, 1)\n",
        "\n",
        "      if np.any(np.isnan(r.detach().numpy())):\n",
        "         print(\"not a number found in the new coordinates\")\n",
        "         break\n",
        "\n",
        "      if np.any(r.detach().numpy() > resolution + 8) or np.any(r.detach().numpy() < -8):\n",
        "         print(\"The agent has left the environment\")\n",
        "         break\n",
        "\n",
        "      if iteration % 1 == 0 and iteration > N_VI_itr:\n",
        "         plot_trajectories(Ulist, environment, dynamics, value)\n",
        "         save_network(net, \"value_net\")\n",
        "\n",
        "      ## Reward ##\n",
        "      new_reward = -dynamics.cost\n",
        "\n",
        "      # Bayesian update\n",
        "      env_VI_loss = environment.env_bayesian_update(env_inference_net, r[:,0], r[:,1])\n",
        "      reward_VI_loss = environment.rew_bayesian_update(reward_inference_net, r[:,0], r[:,1])\n",
        "\n",
        "      ## Information gain ##\n",
        "      if iteration > N_VI_itr:\n",
        "        if step < N_steps - 1:\n",
        "          new_h_mean, new_h_std, new_r_logits = environment.get_statistics() \n",
        "          future_value_map,_ = net.forward(new_h_mean, new_h_std, new_r_logits, N_intergration_steps, g, dt, exploit=exploit)\n",
        "          future_value = environment.extrapolate(r[:,0], r[:,1], future_value_map, \n",
        "                                                 activation=lambda x: x, \n",
        "                                                 derivative=False,\n",
        "                                                 std=.5, \n",
        "                                                 normalized=True).detach()\n",
        "        else:\n",
        "          future_value = new_reward.unsqueeze(1)\n",
        "      \n",
        "      \n",
        "        ## TD kernel ##\n",
        "        arange        = torch.arange(0, environment.resolution).float()\n",
        "        x, y          = torch.meshgrid([arange, arange])\n",
        "        x = x.unsqueeze(0).unsqueeze(0).expand(environment.num_samples,1,environment.resolution,environment.resolution)\n",
        "        y = y.unsqueeze(0).unsqueeze(0).expand(environment.num_samples,1,environment.resolution,environment.resolution)\n",
        "        x0 = old_r[:,0].unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(environment.num_samples,1,environment.resolution,environment.resolution)\n",
        "        y0 = old_r[:,1].unsqueeze(1).unsqueeze(2).unsqueeze(3).expand(environment.num_samples,1,environment.resolution,environment.resolution)\n",
        "        kernel   = torch.exp(-((x - x0) ** 2 + (y - y0) ** 2) / (2 * 3. ** 2))\n",
        "        \n",
        "        ## TD learning ##\n",
        "        loss = net.TDloss(reward, value, future_value, kernel, gamma=0.95)\n",
        "        #loss = net.TD_lambda_loss(reward, value, future_value, kernel, step, gamma=0.95, lam = 0.2)\n",
        "        if not np.isnan(loss.detach().numpy()):\n",
        "          loss.backward(retain_graph=True)\n",
        "          optimizer.step()\n",
        "          environment.generate()\n",
        "          total_loss += float(loss.detach().numpy())\n",
        "          total_reward += float(torch.sum(reward).detach().numpy())\n",
        "        else:\n",
        "          break\n",
        "\n",
        "      ## Reward ##\n",
        "      reward = new_reward\n",
        " \n",
        "      ## VI update ##\n",
        "      if iteration < N_VI_itr:\n",
        "        env_VI_loss.backward(retain_graph=True)\n",
        "        reward_VI_loss.backward(retain_graph=True)\n",
        "        env_VI_loss.backward(retain_graph=True)\n",
        "        reward_VI_loss.backward(retain_graph=True)\n",
        "        env_VI_optimizer.step()\n",
        "        reward_VI_optimizer.step()\n",
        "      total_env_VI_loss += float(env_VI_loss.detach().numpy())\n",
        "      total_reward_VI_loss += float(reward_VI_loss.detach().numpy())\n",
        "   if iteration == N_VI_itr:\n",
        "     save_network(env_inference_net, \"env_net\")\n",
        "     save_network(reward_inference_net, \"reward_net\")\n",
        "     \n",
        "   if iteration > N_VI_itr:\n",
        "     print(\"Reward: {}\".format(total_reward))\n",
        "   else:\n",
        "     print(\"VI env loss: {}\".format(total_env_VI_loss))\n",
        "     print(\"VI rew loss: {}\".format(total_reward_VI_loss))\n",
        "   #loss_list += [loss.detach().numpy()]#\n",
        "   env_VI_loss_list += [total_env_VI_loss]\n",
        "   reward_VI_loss_list += [total_reward_VI_loss]\n",
        "   if iteration == N_VI_itr:\n",
        "     plt.plot(env_VI_loss_list)\n",
        "     plt.show()\n",
        "     plt.plot(reward_VI_loss_list)\n",
        "     plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training inference networks\n",
            "Iteration: 0\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 422241042432.0\n",
            "VI rew loss: 0.22977444529533386\n",
            "Iteration: 1\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 363338297344.0\n",
            "VI rew loss: 0.3573695085942745\n",
            "Iteration: 2\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 406224902144.0\n",
            "VI rew loss: 0.31365251168608665\n",
            "Iteration: 3\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 503899504640.0\n",
            "VI rew loss: 0.2277168594300747\n",
            "Iteration: 4\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 463332421632.0\n",
            "VI rew loss: 0.4688900001347065\n",
            "Iteration: 5\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 406449203200.0\n",
            "VI rew loss: 0.3349279426038265\n",
            "Iteration: 6\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 329373618176.0\n",
            "VI rew loss: 0.2615988291800022\n",
            "Iteration: 7\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 324248328192.0\n",
            "VI rew loss: 0.2598825991153717\n",
            "Iteration: 8\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 320889317376.0\n",
            "VI rew loss: 0.1518800612539053\n",
            "Iteration: 9\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 431204198400.0\n",
            "VI rew loss: 0.27514977008104324\n",
            "Iteration: 10\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 599227244544.0\n",
            "VI rew loss: 0.3366161994636059\n",
            "Iteration: 11\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 466830008320.0\n",
            "VI rew loss: 0.41192008554935455\n",
            "Iteration: 12\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 372196616192.0\n",
            "VI rew loss: 0.26207133010029793\n",
            "Iteration: 13\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 345649184768.0\n",
            "VI rew loss: 0.3933437168598175\n",
            "Iteration: 14\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 379572883456.0\n",
            "VI rew loss: 0.32232655584812164\n",
            "Iteration: 15\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 334715971584.0\n",
            "VI rew loss: 0.1281099859625101\n",
            "Iteration: 16\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 410146734080.0\n",
            "VI rew loss: 0.17513592913746834\n",
            "Iteration: 17\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 556987813888.0\n",
            "VI rew loss: 0.4188919775187969\n",
            "Iteration: 18\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 387728510976.0\n",
            "VI rew loss: 0.21109209023416042\n",
            "Iteration: 19\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 284152754176.0\n",
            "VI rew loss: 0.2820042371749878\n",
            "Iteration: 20\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 328891977728.0\n",
            "VI rew loss: 0.23192789778113365\n",
            "Iteration: 21\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 428531464192.0\n",
            "VI rew loss: 0.2512397300451994\n",
            "Iteration: 22\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 327167698944.0\n",
            "VI rew loss: 0.18166988529264927\n",
            "Iteration: 23\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 245095751680.0\n",
            "VI rew loss: 0.1800212450325489\n",
            "Iteration: 24\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 325475930112.0\n",
            "VI rew loss: 0.2476208209991455\n",
            "Iteration: 25\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 495919110144.0\n",
            "VI rew loss: 0.1512489002197981\n",
            "Iteration: 26\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 422691186688.0\n",
            "VI rew loss: 0.32298579812049866\n",
            "Iteration: 27\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 431805562880.0\n",
            "VI rew loss: 0.1584992278367281\n",
            "Iteration: 28\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 331360634880.0\n",
            "VI rew loss: 0.284047894179821\n",
            "Iteration: 29\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 347667103744.0\n",
            "VI rew loss: 0.29103031381964684\n",
            "Iteration: 30\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 279597538304.0\n",
            "VI rew loss: 0.1230550967156887\n",
            "Iteration: 31\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 356742987776.0\n",
            "VI rew loss: 0.13152461126446724\n",
            "Iteration: 32\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 302686150656.0\n",
            "VI rew loss: 0.19945281837135553\n",
            "Iteration: 33\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 364370180096.0\n",
            "VI rew loss: 0.1612131418660283\n",
            "Iteration: 34\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 253777700864.0\n",
            "VI rew loss: 0.10448094364255667\n",
            "Iteration: 35\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 326113239040.0\n",
            "VI rew loss: 0.25995614007115364\n",
            "Iteration: 36\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 400469547008.0\n",
            "VI rew loss: 0.17383521422743797\n",
            "Iteration: 37\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 384482287616.0\n",
            "VI rew loss: 0.26000647619366646\n",
            "Iteration: 38\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 352392280064.0\n",
            "VI rew loss: 0.09234283957630396\n",
            "Iteration: 39\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 372837822464.0\n",
            "VI rew loss: 0.22625005431473255\n",
            "Iteration: 40\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 355142504448.0\n",
            "VI rew loss: 0.15506913792341948\n",
            "Iteration: 41\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 386779097088.0\n",
            "VI rew loss: 0.16782874427735806\n",
            "Iteration: 42\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 257879505920.0\n",
            "VI rew loss: 0.12468079291284084\n",
            "Iteration: 43\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 504999710720.0\n",
            "VI rew loss: 0.22793004289269447\n",
            "Iteration: 44\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 345266546688.0\n",
            "VI rew loss: 0.3645718451589346\n",
            "Iteration: 45\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 362712178688.0\n",
            "VI rew loss: 0.10626564174890518\n",
            "Iteration: 46\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 307597252608.0\n",
            "VI rew loss: 0.1544069554656744\n",
            "Iteration: 47\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 299287117824.0\n",
            "VI rew loss: 0.3075915165245533\n",
            "Iteration: 48\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 218964445184.0\n",
            "VI rew loss: 0.12400176282972097\n",
            "Iteration: 49\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 314679769088.0\n",
            "VI rew loss: 0.27946700528264046\n",
            "Iteration: 50\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 290103347200.0\n",
            "VI rew loss: 0.26787421852350235\n",
            "Iteration: 51\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 317938165760.0\n",
            "VI rew loss: 0.1698973085731268\n",
            "Iteration: 52\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 266827040768.0\n",
            "VI rew loss: 0.22994031198322773\n",
            "Iteration: 53\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 288600600576.0\n",
            "VI rew loss: 0.14216136373579502\n",
            "Iteration: 54\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 387605450752.0\n",
            "VI rew loss: 0.16833274438977242\n",
            "Iteration: 55\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 280434954240.0\n",
            "VI rew loss: 0.3196103163063526\n",
            "Iteration: 56\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 297720780800.0\n",
            "VI rew loss: 0.24131536297500134\n",
            "Iteration: 57\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 338474053632.0\n",
            "VI rew loss: 0.3960975222289562\n",
            "Iteration: 58\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 291983589376.0\n",
            "VI rew loss: 0.23704572021961212\n",
            "Iteration: 59\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 383311239168.0\n",
            "VI rew loss: 0.548185508698225\n",
            "Iteration: 60\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 243736281088.0\n",
            "VI rew loss: 0.22616184502840042\n",
            "Iteration: 61\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 325990029312.0\n",
            "VI rew loss: 0.41880902647972107\n",
            "Iteration: 62\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 250841183232.0\n",
            "VI rew loss: 0.37355637177824974\n",
            "Iteration: 63\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 296662966272.0\n",
            "VI rew loss: 0.11925788037478924\n",
            "Iteration: 64\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 208515145728.0\n",
            "VI rew loss: 0.14472386240959167\n",
            "Iteration: 65\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 271639558144.0\n",
            "VI rew loss: 0.044586863834410906\n",
            "Iteration: 66\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 342637772800.0\n",
            "VI rew loss: 0.20737509429454803\n",
            "Iteration: 67\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 275305840640.0\n",
            "VI rew loss: 0.17766628228127956\n",
            "Iteration: 68\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 299629541376.0\n",
            "VI rew loss: 0.26301489770412445\n",
            "Iteration: 69\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 311327367168.0\n",
            "VI rew loss: 0.40310613438487053\n",
            "Iteration: 70\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 323407099904.0\n",
            "VI rew loss: 0.16575668193399906\n",
            "Iteration: 71\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 292913217536.0\n",
            "VI rew loss: 0.08973224135115743\n",
            "Iteration: 72\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 300654759936.0\n",
            "VI rew loss: 0.2280220314860344\n",
            "Iteration: 73\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 265091639296.0\n",
            "VI rew loss: 0.15607992466539145\n",
            "Iteration: 74\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 311091361792.0\n",
            "VI rew loss: 0.23023258335888386\n",
            "Iteration: 75\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 243729571840.0\n",
            "VI rew loss: 0.2135176956653595\n",
            "Iteration: 76\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 252062138368.0\n",
            "VI rew loss: 0.21704638563096523\n",
            "Iteration: 77\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 263157078016.0\n",
            "VI rew loss: 0.10274959355592728\n",
            "Iteration: 78\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 209720863744.0\n",
            "VI rew loss: 0.09429359808564186\n",
            "Iteration: 79\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 278086975488.0\n",
            "VI rew loss: 0.12100488226860762\n",
            "Iteration: 80\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 277860771840.0\n",
            "VI rew loss: 0.3146333023905754\n",
            "Iteration: 81\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 252288149504.0\n",
            "VI rew loss: 0.0729137696325779\n",
            "Iteration: 82\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 251148991488.0\n",
            "VI rew loss: 0.16064060665667057\n",
            "Iteration: 83\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 388054022144.0\n",
            "VI rew loss: 0.16084175743162632\n",
            "Iteration: 84\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 320258871296.0\n",
            "VI rew loss: 0.15457004494965076\n",
            "Iteration: 85\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 311282382848.0\n",
            "VI rew loss: 0.1759900562465191\n",
            "Iteration: 86\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 210271819776.0\n",
            "VI rew loss: 0.08436768176034093\n",
            "Iteration: 87\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 347898050560.0\n",
            "VI rew loss: 0.2945910058915615\n",
            "Iteration: 88\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 250873032704.0\n",
            "VI rew loss: 0.09418028965592384\n",
            "Iteration: 89\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 224809363456.0\n",
            "VI rew loss: 0.12277084775269032\n",
            "Iteration: 90\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 313884364800.0\n",
            "VI rew loss: 0.1169918766245246\n",
            "Iteration: 91\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 260794517504.0\n",
            "VI rew loss: 0.15752853825688362\n",
            "Iteration: 92\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 259567470592.0\n",
            "VI rew loss: 0.1794869713485241\n",
            "Iteration: 93\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 254978786304.0\n",
            "VI rew loss: 0.14608252700418234\n",
            "Iteration: 94\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 304380997632.0\n",
            "VI rew loss: 0.0948259886354208\n",
            "Iteration: 95\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 246424089600.0\n",
            "VI rew loss: 0.12562525551766157\n",
            "Iteration: 96\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 235872679936.0\n",
            "VI rew loss: 0.1546556055545807\n",
            "Iteration: 97\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 177659305984.0\n",
            "VI rew loss: 0.12247939733788371\n",
            "Iteration: 98\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 186939974656.0\n",
            "VI rew loss: 0.126647075638175\n",
            "Iteration: 99\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 200215781376.0\n",
            "VI rew loss: 0.0741526186466217\n",
            "Iteration: 100\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 235366174720.0\n",
            "VI rew loss: 0.16793852858245373\n",
            "Iteration: 101\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 197952548864.0\n",
            "VI rew loss: 0.20960192382335663\n",
            "Iteration: 102\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 218434132992.0\n",
            "VI rew loss: 0.12977863289415836\n",
            "Iteration: 103\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 226767673344.0\n",
            "VI rew loss: 0.13524346705526114\n",
            "Iteration: 104\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 224943609856.0\n",
            "VI rew loss: 0.14345323853194714\n",
            "Iteration: 105\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 195309808640.0\n",
            "VI rew loss: 0.1665120478719473\n",
            "Iteration: 106\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 188563872768.0\n",
            "VI rew loss: 0.07744942884892225\n",
            "Iteration: 107\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 251534471168.0\n",
            "VI rew loss: 0.07055568415671587\n",
            "Iteration: 108\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 264792907776.0\n",
            "VI rew loss: 0.09083531238138676\n",
            "Iteration: 109\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 273540591616.0\n",
            "VI rew loss: 0.15185515582561493\n",
            "Iteration: 110\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 220999151616.0\n",
            "VI rew loss: 0.12703965418040752\n",
            "Iteration: 111\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 157107107840.0\n",
            "VI rew loss: 0.13024388067424297\n",
            "Iteration: 112\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 205792893952.0\n",
            "VI rew loss: 0.16463632136583328\n",
            "Iteration: 113\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 232634999808.0\n",
            "VI rew loss: 0.14512335322797298\n",
            "Iteration: 114\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 223813782528.0\n",
            "VI rew loss: 0.15403230674564838\n",
            "Iteration: 115\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 197662590976.0\n",
            "VI rew loss: 0.19239988923072815\n",
            "Iteration: 116\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 261058787328.0\n",
            "VI rew loss: 0.19355552829802036\n",
            "Iteration: 117\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 318425749504.0\n",
            "VI rew loss: 0.24338914081454277\n",
            "Iteration: 118\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 259062024192.0\n",
            "VI rew loss: 0.15762257017195225\n",
            "Iteration: 119\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 137693451264.0\n",
            "VI rew loss: 0.11716791056096554\n",
            "Iteration: 120\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 223001248768.0\n",
            "VI rew loss: 0.189112838357687\n",
            "Iteration: 121\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 173881904128.0\n",
            "VI rew loss: 0.20825589448213577\n",
            "Iteration: 122\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 237359257600.0\n",
            "VI rew loss: 0.09055909235030413\n",
            "Iteration: 123\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 221920707584.0\n",
            "VI rew loss: 0.1466216128319502\n",
            "Iteration: 124\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 238442391552.0\n",
            "VI rew loss: 0.14865458011627197\n",
            "Iteration: 125\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 251549864960.0\n",
            "VI rew loss: 0.17364568449556828\n",
            "Iteration: 126\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 210052461568.0\n",
            "VI rew loss: 0.09903262555599213\n",
            "Iteration: 127\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 291537330176.0\n",
            "VI rew loss: 0.2197326086461544\n",
            "Iteration: 128\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 292872159232.0\n",
            "VI rew loss: 0.423222903162241\n",
            "Iteration: 129\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 219923607552.0\n",
            "VI rew loss: 0.237300094217062\n",
            "Iteration: 130\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 203433575424.0\n",
            "VI rew loss: 0.10616797022521496\n",
            "Iteration: 131\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 255351126016.0\n",
            "VI rew loss: 0.11670284625142813\n",
            "Iteration: 132\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 263147750400.0\n",
            "VI rew loss: 0.2487430591136217\n",
            "Iteration: 133\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 237638004736.0\n",
            "VI rew loss: 0.14700455404818058\n",
            "Iteration: 134\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 154095174656.0\n",
            "VI rew loss: 0.14485059678554535\n",
            "Iteration: 135\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 230348187648.0\n",
            "VI rew loss: 0.08348592184484005\n",
            "Iteration: 136\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 274861852672.0\n",
            "VI rew loss: 0.18045745603740215\n",
            "Iteration: 137\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 163953880064.0\n",
            "VI rew loss: 0.04714646772481501\n",
            "Iteration: 138\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 177214498816.0\n",
            "VI rew loss: 0.11933653615415096\n",
            "Iteration: 139\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 242643411968.0\n",
            "VI rew loss: 0.21889785304665565\n",
            "Iteration: 140\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 231277849600.0\n",
            "VI rew loss: 0.1936682015657425\n",
            "Iteration: 141\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 267530881024.0\n",
            "VI rew loss: 0.20375876873731613\n",
            "Iteration: 142\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 222792286208.0\n",
            "VI rew loss: 0.15997080132365227\n",
            "Iteration: 143\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 212910878720.0\n",
            "VI rew loss: 0.15422696247696877\n",
            "Iteration: 144\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 276364955648.0\n",
            "VI rew loss: 0.12787541188299656\n",
            "Iteration: 145\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 200667377664.0\n",
            "VI rew loss: 0.13114825822412968\n",
            "Iteration: 146\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 177303565312.0\n",
            "VI rew loss: 0.14015917479991913\n",
            "Iteration: 147\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 194966250496.0\n",
            "VI rew loss: 0.15553545951843262\n",
            "Iteration: 148\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 161703487488.0\n",
            "VI rew loss: 0.046514492481946945\n",
            "Iteration: 149\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 162743533568.0\n",
            "VI rew loss: 0.1256493367254734\n",
            "Iteration: 150\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 180307544064.0\n",
            "VI rew loss: 0.13028662092983723\n",
            "Iteration: 151\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 143436824576.0\n",
            "VI rew loss: 0.0729379877448082\n",
            "Iteration: 152\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 158047774720.0\n",
            "VI rew loss: 0.13202457502484322\n",
            "Iteration: 153\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 160865912832.0\n",
            "VI rew loss: 0.11977975815534592\n",
            "Iteration: 154\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 243217292288.0\n",
            "VI rew loss: 0.338142529129982\n",
            "Iteration: 155\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 190414811136.0\n",
            "VI rew loss: 0.13180006109178066\n",
            "Iteration: 156\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 211875233792.0\n",
            "VI rew loss: 0.13611100055277348\n",
            "Iteration: 157\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 211724924928.0\n",
            "VI rew loss: 0.14755660854279995\n",
            "Iteration: 158\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 159070516224.0\n",
            "VI rew loss: 0.036795263178646564\n",
            "Iteration: 159\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 205586465792.0\n",
            "VI rew loss: 0.14636026788502932\n",
            "Iteration: 160\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 176324969472.0\n",
            "VI rew loss: 0.12976064160466194\n",
            "Iteration: 161\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 188818952192.0\n",
            "VI rew loss: 0.1015365794301033\n",
            "Iteration: 162\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 159882921984.0\n",
            "VI rew loss: 0.09688875824213028\n",
            "Iteration: 163\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 142191460352.0\n",
            "VI rew loss: 0.0834064818918705\n",
            "Iteration: 164\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 193941487616.0\n",
            "VI rew loss: 0.14115168899297714\n",
            "Iteration: 165\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 187716227072.0\n",
            "VI rew loss: 0.13645023480057716\n",
            "Iteration: 166\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 201279457280.0\n",
            "VI rew loss: 0.14414941146969795\n",
            "Iteration: 167\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 166751292416.0\n",
            "VI rew loss: 0.1092663798481226\n",
            "Iteration: 168\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 202776832000.0\n",
            "VI rew loss: 0.11920296214520931\n",
            "Iteration: 169\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 172753268736.0\n",
            "VI rew loss: 0.10153256356716156\n",
            "Iteration: 170\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 152422607872.0\n",
            "VI rew loss: 0.07899864763021469\n",
            "Iteration: 171\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 194046680064.0\n",
            "VI rew loss: 0.13171088136732578\n",
            "Iteration: 172\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 181543312384.0\n",
            "VI rew loss: 0.08212419878691435\n",
            "Iteration: 173\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 215730048000.0\n",
            "VI rew loss: 0.1836035344749689\n",
            "Iteration: 174\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 189160587264.0\n",
            "VI rew loss: 0.1037248931825161\n",
            "Iteration: 175\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 151342760960.0\n",
            "VI rew loss: 0.0796581357717514\n",
            "Iteration: 176\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 169695935488.0\n",
            "VI rew loss: 0.09321767557412386\n",
            "Iteration: 177\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 187097515008.0\n",
            "VI rew loss: 0.197247426956892\n",
            "Iteration: 178\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 165082457088.0\n",
            "VI rew loss: 0.2014260347932577\n",
            "Iteration: 179\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 180271771648.0\n",
            "VI rew loss: 0.15344606153666973\n",
            "Iteration: 180\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 172187925504.0\n",
            "VI rew loss: 0.07085285754874349\n",
            "Iteration: 181\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 168501903360.0\n",
            "VI rew loss: 0.12880539149045944\n",
            "Iteration: 182\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 240736499712.0\n",
            "VI rew loss: 0.23562602326273918\n",
            "Iteration: 183\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 214326153216.0\n",
            "VI rew loss: 0.14820203557610512\n",
            "Iteration: 184\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 116309394432.0\n",
            "VI rew loss: 0.09848964959383011\n",
            "Iteration: 185\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 111974277120.0\n",
            "VI rew loss: 0.0717665278352797\n",
            "Iteration: 186\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 223457343488.0\n",
            "VI rew loss: 0.16117745079100132\n",
            "Iteration: 187\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 199779919872.0\n",
            "VI rew loss: 0.11707193963229656\n",
            "Iteration: 188\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 145722027008.0\n",
            "VI rew loss: 0.09165756683796644\n",
            "Iteration: 189\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 182713269248.0\n",
            "VI rew loss: 0.11017641052603722\n",
            "Iteration: 190\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 170021246976.0\n",
            "VI rew loss: 0.21075423434376717\n",
            "Iteration: 191\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 134302699520.0\n",
            "VI rew loss: 0.08830343699082732\n",
            "Iteration: 192\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 168613201920.0\n",
            "VI rew loss: 0.13336113281548023\n",
            "Iteration: 193\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 166641993728.0\n",
            "VI rew loss: 0.10129086952656507\n",
            "Iteration: 194\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 131544517632.0\n",
            "VI rew loss: 0.09604766219854355\n",
            "Iteration: 195\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 223332646912.0\n",
            "VI rew loss: 0.12269244901835918\n",
            "Iteration: 196\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 211613865984.0\n",
            "VI rew loss: 0.047410584054887295\n",
            "Iteration: 197\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 160052350976.0\n",
            "VI rew loss: 0.09252642188221216\n",
            "Iteration: 198\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 162992409600.0\n",
            "VI rew loss: 0.09809926757588983\n",
            "Iteration: 199\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 221051548672.0\n",
            "VI rew loss: 0.3039240464568138\n",
            "Iteration: 200\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 167057232896.0\n",
            "VI rew loss: 0.13129697181284428\n",
            "Iteration: 201\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 163935376384.0\n",
            "VI rew loss: 0.11697721853852272\n",
            "Iteration: 202\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 188907688960.0\n",
            "VI rew loss: 0.2334849312901497\n",
            "Iteration: 203\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 193946085376.0\n",
            "VI rew loss: 0.20327800326049328\n",
            "Iteration: 204\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 181984690176.0\n",
            "VI rew loss: 0.12707754410803318\n",
            "Iteration: 205\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 110849291264.0\n",
            "VI rew loss: 0.05485659744590521\n",
            "Iteration: 206\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 186725289984.0\n",
            "VI rew loss: 0.19602025486528873\n",
            "Iteration: 207\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 163301622784.0\n",
            "VI rew loss: 0.14630595594644547\n",
            "Iteration: 208\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 182152700928.0\n",
            "VI rew loss: 0.28762832656502724\n",
            "Iteration: 209\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 145919255552.0\n",
            "VI rew loss: 0.16769177466630936\n",
            "Iteration: 210\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 165326085120.0\n",
            "VI rew loss: 0.06580573692917824\n",
            "Iteration: 211\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 180111609856.0\n",
            "VI rew loss: 0.13163764774799347\n",
            "Iteration: 212\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 157638571008.0\n",
            "VI rew loss: 0.13601440843194723\n",
            "Iteration: 213\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 252460478464.0\n",
            "VI rew loss: 0.08851789310574532\n",
            "Iteration: 214\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 157396128768.0\n",
            "VI rew loss: 0.08676579035818577\n",
            "Iteration: 215\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 246121678848.0\n",
            "VI rew loss: 0.224672494456172\n",
            "Iteration: 216\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 228339559424.0\n",
            "VI rew loss: 0.12695945799350739\n",
            "Iteration: 217\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 163975071744.0\n",
            "VI rew loss: 0.20647362247109413\n",
            "Iteration: 218\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 194859476992.0\n",
            "VI rew loss: 0.15751700475811958\n",
            "Iteration: 219\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 202465806336.0\n",
            "VI rew loss: 0.19170633144676685\n",
            "Iteration: 220\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 133770531840.0\n",
            "VI rew loss: 0.10051118582487106\n",
            "Iteration: 221\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 129822797824.0\n",
            "VI rew loss: 0.18532654829323292\n",
            "Iteration: 222\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 136019631104.0\n",
            "VI rew loss: 0.08428459474816918\n",
            "Iteration: 223\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 189418385408.0\n",
            "VI rew loss: 0.09865020588040352\n",
            "Iteration: 224\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 173184151552.0\n",
            "VI rew loss: 0.18365289829671383\n",
            "Iteration: 225\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 127852124160.0\n",
            "VI rew loss: 0.2313352096825838\n",
            "Iteration: 226\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 179202219008.0\n",
            "VI rew loss: 0.07749115861952305\n",
            "Iteration: 227\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 148518419456.0\n",
            "VI rew loss: 0.14466810785233974\n",
            "Iteration: 228\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 132018975744.0\n",
            "VI rew loss: 0.17731979116797447\n",
            "Iteration: 229\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 173103526912.0\n",
            "VI rew loss: 0.18274514749646187\n",
            "Iteration: 230\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 149813666816.0\n",
            "VI rew loss: 0.09398133913055062\n",
            "Iteration: 231\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 196948517888.0\n",
            "VI rew loss: 0.11534114368259907\n",
            "Iteration: 232\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 196643662848.0\n",
            "VI rew loss: 0.1786652859300375\n",
            "Iteration: 233\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 133529669632.0\n",
            "VI rew loss: 0.09851820580661297\n",
            "Iteration: 234\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 183093883904.0\n",
            "VI rew loss: 0.1578165302053094\n",
            "Iteration: 235\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 165705619456.0\n",
            "VI rew loss: 0.2236646618694067\n",
            "Iteration: 236\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 132358703104.0\n",
            "VI rew loss: 0.1223121676594019\n",
            "Iteration: 237\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 203255888896.0\n",
            "VI rew loss: 0.29121827706694603\n",
            "Iteration: 238\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 147219161088.0\n",
            "VI rew loss: 0.09123740158975124\n",
            "Iteration: 239\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 177358277632.0\n",
            "VI rew loss: 0.11394925601780415\n",
            "Iteration: 240\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 112963330560.0\n",
            "VI rew loss: 0.07142686937004328\n",
            "Iteration: 241\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 149064308736.0\n",
            "VI rew loss: 0.11055933870375156\n",
            "Iteration: 242\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 160167857152.0\n",
            "VI rew loss: 0.14458773285150528\n",
            "Iteration: 243\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 145258217472.0\n",
            "VI rew loss: 0.09411309938877821\n",
            "Iteration: 244\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 133913212416.0\n",
            "VI rew loss: 0.06532234698534012\n",
            "Iteration: 245\n",
            "Step: 0\n",
            "Step: 1\n",
            "Step: 2\n",
            "Step: 3\n",
            "Step: 4\n",
            "VI env loss: 142535607296.0\n",
            "VI rew loss: 0.06529761338606477\n",
            "Iteration: 246\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}